{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning for sentiment CSV -> produce `stock.csv`\n",
    "# Steps:\n",
    "# - find latest `sentiment_stock_news_*.csv`\n",
    "# - normalize columns (dates, strings, numeric scores)\n",
    "# - standardize recommendations to Buy/Sell/Hold\n",
    "# - drop duplicates (symbol + title + published)\n",
    "# - save cleaned file as `stock.csv`\n",
    "\n",
    "import os, glob, sys, subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# ensure pandas installed\n",
    "def ensure_pkg(module_name, pip_name=None):\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "    except ImportError:\n",
    "        name = pip_name if pip_name else module_name\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', name])\n",
    "\n",
    "ensure_pkg('pandas')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Locate latest sentiment CSV\n",
    "pattern = os.path.join(os.getcwd(), 'sentiment_stock_news_*.csv')\n",
    "files = sorted(glob.glob(pattern))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f'No sentiment CSV files found with pattern: {pattern}')\n",
    "\n",
    "sent_file = files[-1]\n",
    "print('Loading:', sent_file)\n",
    "\n",
    "# Read CSV (be permissive about parsing)\n",
    "df = pd.read_csv(sent_file, dtype=str, keep_default_na=False)\n",
    "orig_rows = len(df)\n",
    "\n",
    "# Normalize column names (lowercase keys) and ensure expected columns exist\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "expected = ['date','company','symbol','title','source','published','url','sentiment_score','recommendation']\n",
    "for col in expected:\n",
    "    if col not in df.columns:\n",
    "        df[col] = ''\n",
    "\n",
    "# Trim whitespace for string columns\n",
    "str_cols = ['company','symbol','title','source','url','recommendation']\n",
    "for c in str_cols:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Parse dates: 'date' (store as YYYY-MM-DD) and 'published' (ISO timestamp)\n",
    "df['date_parsed'] = pd.to_datetime(df['date'], errors='coerce').dt.date\n",
    "# try parsing 'published' to timezone-aware datetime where possible; keep as ISO string\n",
    "df['published_parsed'] = pd.to_datetime(df['published'], errors='coerce', utc=True)\n",
    "\n",
    "# Convert sentiment_score to float\n",
    "df['sentiment_score'] = pd.to_numeric(df['sentiment_score'], errors='coerce')\n",
    "\n",
    "# Standardize recommendation values to Buy/Hold/Sell\n",
    "df['recommendation_clean'] = df['recommendation'].str.title().where(df['recommendation'].notna(), '')\n",
    "# Map common variants if any (extendable)\n",
    "valid = {'Buy','Sell','Hold'}\n",
    "df['recommendation_clean'] = df['recommendation_clean'].apply(lambda x: x if x in valid else 'Hold')\n",
    "\n",
    "# Drop rows without symbol or date\n",
    "before_drop = len(df)\n",
    "df = df[df['symbol'].astype(bool) & df['date_parsed'].notna()].copy()\n",
    "after_drop = len(df)\n",
    "\n",
    "# Drop duplicates by (symbol, title, published_parsed) where title or published exist\n",
    "# Create a dedupe key\n",
    "df['dedupe_key'] = df['symbol'].str.upper() + '|' + df['title'].fillna('') + '|' + df['published_parsed'].astype(str)\n",
    "df = df.drop_duplicates(subset=['dedupe_key'], keep='first').copy()\n",
    "\n",
    "# Prepare final cleaned DataFrame with chosen column names\n",
    "clean = pd.DataFrame({\n",
    "    'date': df['date_parsed'].astype(str),\n",
    "    'company': df['company'],\n",
    "    'symbol': df['symbol'],\n",
    "    'title': df['title'],\n",
    "    'source': df['source'],\n",
    "    'published': df['published_parsed'].dt.strftime('%Y-%m-%dT%H:%M:%SZ').fillna(''),\n",
    "    'url': df['url'],\n",
    "    'sentiment_score': df['sentiment_score'],\n",
    "    'recommendation': df['recommendation_clean']\n",
    "})\n",
    "\n",
    "# Save to stock.csv\n",
    "out_path = os.path.join(os.getcwd(), 'stock.csv')\n",
    "clean.to_csv(out_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f'Original rows: {orig_rows}')\n",
    "print(f'Rows after removing missing symbol/date: {after_drop} (removed {before_drop - after_drop})')\n",
    "print(f'Rows after deduplication: {len(clean)}')\n",
    "print('\\nRecommendation counts:')\n",
    "print(clean['recommendation'].value_counts(dropna=False))\n",
    "print('\\nDate range: ', clean['date'].min(), '->', clean['date'].max())\n",
    "print('\\nSaved cleaned data to', out_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
